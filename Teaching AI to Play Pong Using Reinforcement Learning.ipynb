{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d03b6c56",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f89fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pretty standard stuff here\n",
    "\n",
    "!mkdir PongReinforcementLearning\n",
    "!cd PongReinforcementLearning\n",
    "\n",
    "# Then, I set up a virtual environment (venv)\n",
    "python -m venv PongReinforcementLearningVENV\n",
    "!source PongReinforcementLearningVENV/bin/activate\n",
    "\n",
    "# Make the venv recognizable to Jupyter Notebooks.\n",
    "# This is the bridge that connects Jupyter to my isolated Python environment.\n",
    "%pip install ipyconfig\n",
    "python -m ipykernel install --user --name=PongReinforcementLearningVENV\n",
    "\n",
    "# Time to fire up Jupyter Notebook.\n",
    "# Make sure to select the new venv as the Python interpreter.\n",
    "jupyter notebook\n",
    "\n",
    "# Finally, installing some libs, i usually do these via the console but Jupyter's % operator usually works just fine\n",
    "%pip3 install pygame\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e54589",
   "metadata": {},
   "source": [
    "# See if I can run an external Pygame window from a Jupyter notebook on macosx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ecbdd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.1 (SDL 2.28.2, Python 3.10.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "pygame.init()\n",
    "\n",
    "# Create external window\n",
    "win = pygame.display.set_mode((500, 500))\n",
    "\n",
    "# Main game loop\n",
    "run = True\n",
    "while run:\n",
    "    pygame.time.delay(100)\n",
    "    \n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            run = False\n",
    "            \n",
    "    # Game logic here (e.g., move a rectangle)\n",
    "    pygame.draw.rect(win, (255, 0, 0), (250, 250, 50, 50))\n",
    "    \n",
    "    pygame.display.update()\n",
    "\n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dae897a",
   "metadata": {},
   "source": [
    "**Well, it runs but shutdown isn't graceful.  The window pops up, draws a glorious red square.  But then simple window commands like \"close\" fail.  I had to Force Quit which then also brought the Jupyter notebook kernel to the ground.  This may wind up being a royal PITA but i'll give it a shot for now.  Worst case I'll switch to a simple python script run from the console.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad09609",
   "metadata": {},
   "source": [
    "# Pong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8d21b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.1 (SDL 2.28.2, Python 3.10.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 3, 1) and action 1: 0.9729657907733198\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 3, 1) and action 0: 0.4788019483939463\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 0.8279742648620194\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 0.7359454468436755\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -0.3708819291286616\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -0.9745759348609289\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 0.4139871324310097\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 0.9458127734606654\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 0.5228092727245977\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -0.48728796743046443\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 0.20699356621550485\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 0.36797272342183773\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 0.2614046363622988\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 0.18398636171091887\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 0.10349678310775243\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 0.4729063867303327\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -0.1854409645643308\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 0.23645319336516635\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -0.0927204822821654\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 0.11822659668258317\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 0.1307023181811494\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -0.24364398371523222\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 0.051748391553876213\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 0.05911329834129159\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -0.0463602411410827\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -0.12182199185761611\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 0.0653511590905747\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -0.060910995928808054\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 0.03267557954528735\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -0.030455497964404027\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 0.016337789772643677\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 0.09199318085545943\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 0.025874195776938107\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -0.015227748982202013\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -0.02318012057054135\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 0.04599659042772972\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 0.012937097888469053\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -0.007613874491101007\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -0.011590060285270674\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -0.0038069372455505034\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -0.005795030142635337\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 0.029556649170645793\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -0.0028975150713176686\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -0.0019034686227752517\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 0.006468548944234527\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 0.02299829521386486\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -0.0014487575356588343\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 0.014778324585322897\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 0.008168894886321838\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -0.0009517343113876258\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 2, 1) and action 1: -0.5896273811661399\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 2, 1) and action 2: 0.2722360396954624\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 2: -0.5731636557083697\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -0.14599051352294934\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 1: 0.4232728909621639\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -0.07299525676147467\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 0.9303389768556498\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -0.036497628380737335\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 0: -0.4815083751800249\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -0.018248814190368667\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 1: 0.21163644548108196\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 1: -0.2767860627336136\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 2: -0.28658182785418485\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -0.5842421306126535\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 1: 0.10581822274054098\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 1: -0.1383930313668068\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 0.10584610546102624\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -0.29212106530632675\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -0.05282799041311237\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -0.14606053265316338\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -0.026413995206556184\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 0.13314059443776904\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -0.013206997603278092\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 0.1290880014902276\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 0.05292305273051312\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 0.0645440007451138\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -0.006603498801639046\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 0.06657029721888452\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 0.02646152636525656\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 0.03328514860944226\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 0.01323076318262828\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 0.01664257430472113\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 0.4651694884278249\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -0.009124407095184334\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 0.23258474421391245\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -0.004562203547592167\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 0.00661538159131414\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 0.0322720003725569\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 0.11629237210695623\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -0.0022811017737960834\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 0.05814618605347811\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -0.0011405508868980417\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 0.029073093026739057\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 1: -0.0691965156834034\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 1: 0.05290911137027049\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -0.07303026632658169\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 0.014536546513369528\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 2: -0.10540534067495555\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 1: 0.026454555685135245\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 1: -0.0345982578417017\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 1, 1) and action 0: 0.39237870716106804\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 1, 1) and action 0: -0.8217572859130133\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 1) and action 1: 0.013832663947630053\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 2: 0.8570081475642428\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 2: 0.47257419512226506\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 2: 0.4285040737821214\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 1: 0.08471771941708384\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 0: -0.2737274756637338\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 1: 0.04235885970854192\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 2: -0.6973342401171563\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 2: 0.23628709756113253\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -0.3769181770493719\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 2: 0.11814354878056627\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -0.18845908852468596\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 0: -0.7005556830491657\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 2: -0.34866712005857814\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 2: 0.05907177439028313\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -0.09422954426234298\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 1: 0.02117942985427096\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -0.04711477213117149\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 1: 0.01058971492713548\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -0.9297536867855356\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 1: 0.00529485746356774\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 2: -0.17433356002928907\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 2: 0.029535887195141566\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -0.4648768433927678\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 1: 0.00264742873178387\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -0.2324384216963839\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 0: -0.35027784152458286\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -0.11621921084819195\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 2: 0.014767943597570783\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -0.058109605424095975\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 0: -0.17513892076229143\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 0: -0.1368637378318669\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 0: -0.08756946038114571\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -0.023557386065585745\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 1: 0.001323714365891935\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 2: -0.08716678001464453\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 0: -0.04378473019057286\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -0.029054802712047988\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 0: -0.02189236509528643\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -0.011778693032792872\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 2: 0.007383971798785392\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 2: -0.04358339000732227\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 0: -0.010946182547643214\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -0.005889346516396436\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 2: 0.003691985899392696\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -0.002944673258198218\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 0: -0.005473091273821607\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 2: -0.021791695003661134\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 1: -0.006047986634533098\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 1: -0.9745222293402822\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 7, 0, 0) and action 1: 0.8752544410373608\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -0.5250700242607331\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 7, 0, 0) and action 2: -0.5666228797841286\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -0.26253501213036656\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 7, 0, 0) and action 0: -0.9425213043258296\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -0.13126750606518328\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 7, 0, 0) and action 1: 0.4376272205186804\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 2: 0.03335000822564571\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 7, 0, 0) and action 2: -0.2833114398920643\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 1: -0.4872611146701411\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 7, 0, 0) and action 0: -0.4712606521629148\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -0.06563375303259164\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 7, 0, 0) and action 0: -0.2356303260814574\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 2: 0.016675004112822855\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 0: -0.38031915066563027\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -0.03281687651629582\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 0: -0.19015957533281513\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -0.01640843825814791\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 2: -0.009367119191799889\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 0: 0.597187734650884\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 2: -0.004683559595899944\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 1: 0.39570229827546743\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 1: -0.003023993317266549\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 2: 0.22170142268481619\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 0: -0.09507978766640757\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 0: 0.298593867325442\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 0: -0.047539893833203783\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 0: 0.149296933662721\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 2: -0.002341779797949972\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 2: 0.11085071134240809\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 0: -0.023769946916601892\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 0: 0.0746484668313605\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 2: -0.001170889898974986\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 2: 0.055425355671204046\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 1: -0.0015119966586332745\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 2: 0.027712677835602023\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 1: -0.0007559983293166372\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 1: 0.19785114913773372\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 0: -0.011884973458300946\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 1: 0.09892557456886686\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 2: -0.000585444949487493\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 0: 0.03732423341568025\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 1: -0.0003779991646583186\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 0: 0.018662116707840126\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 1: -0.0001889995823291593\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 1: 0.04946278728443343\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 1: -9.449979116457966e-05\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 0: 0.009331058353920063\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 8, 1, 0) and action 0: -0.15353142037762413\n",
      "Debug: Before Update - Q_value Right for state (1, 8, 1, 0) and action 2: 0.30386305565986027\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 1, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: -1, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 3, 1) and action 0: 0.8767782953342762\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 3, 1) and action 0: 0.23940097419697315\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -0.0007243787678294171\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 0.01149914760693243\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 0.0032342744721172633\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 0.007389162292661448\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 0.004084447443160919\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 0.005749573803466215\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 0.0020422237215804596\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 0.003694581146330724\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -0.0003621893839147086\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 0.0028747869017331073\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 0.0016171372360586317\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 0.0014373934508665536\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 0.0010211118607902298\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 0.0007186967254332768\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -0.0001810946919573543\n",
      "Debug: Before Update - Q_value Right for state (1, 4, 2, 1) and action 1: 0.32701894339265847\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 0.0005105559303951149\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 0.001847290573165362\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 0.00025527796519755745\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 0.000923645286582681\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 0.0008085686180293158\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 0.0003593483627166384\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -9.054734597867714e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -0.0004758671556938129\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 0.0004042843090146579\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 0.0004618226432913405\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 0.00012763898259877872\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 0.0001796741813583192\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 6.381949129938936e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 0.00023091132164567026\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 0.00020214215450732896\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -0.00023793357784690646\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 0.00010107107725366448\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -0.00011896678892345323\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 5.053553862683224e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 8.98370906791596e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 4, 2, 1) and action 1: -0.4085842021680455\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -5.9483394461726615e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 3.190974564969468e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -2.9741697230863308e-05\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 2.526776931341612e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 0.00011545566082283513\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 4, 2, 1) and action 2: -0.6795772388643286\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 5.7727830411417565e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 4, 2, 1) and action 1: -0.20429210108402274\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 2.8863915205708783e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -4.527367298933857e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 1.4431957602854391e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 2, 1) and action 2: -0.6581187702481959\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 2, 1) and action 1: 0.8177007104604057\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 2: -0.14329091392709242\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 0.01613600018627845\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 2: -0.07164545696354621\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 0.008321287152360565\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 2: -0.035822728481773106\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 0.004160643576180283\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 2: -0.017911364240886553\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -0.0005702754434490209\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 2: -0.008955682120443276\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 0.0020803217880901413\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 1: 0.013227277842567622\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 0.0010401608940450707\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 2: -0.004477841060221638\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -0.00028513772172451043\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 0: -0.24075418759001244\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -0.036515133163290844\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 2: -0.002238920530110819\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 0.008068000093139224\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 0: -0.12037709379500622\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -0.00014256886086225521\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 0: -0.06018854689750311\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -7.128443043112761e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 1: -0.05565598595485066\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 1: -0.01729912892085085\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 5, 1, 1) and action 0: -0.030094273448751555\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -0.018257566581645422\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 0: 0.39100902664290627\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -0.009128783290822711\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 2: 0.23911815725608143\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 0.0005200804470225353\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 0: 0.19550451332145313\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 0.00026004022351126766\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 1: -0.02782799297742533\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 0.004034000046569612\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 2: 0.11955907862804072\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -3.5642215215563803e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 2: 0.05977953931402036\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 0.00013002011175563383\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 2: 0.02988976965701018\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 0.002017000023284806\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 2: 0.01494488482850509\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 6.501005587781692e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 2: 0.007472442414252545\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 3.250502793890846e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 0: 0.09775225666072657\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 0.001008500011642403\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 1: -0.013913996488712665\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 1.625251396945423e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 1, 1) and action 2: -0.029393565815994505\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 1, 1) and action 0: 0.8886506635264755\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 2: -0.021043645404854816\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -0.001472336629099109\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 1: 0.7073205664796787\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 2: -0.010895847501830567\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 2: -0.010521822702427408\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -0.0007361683145495545\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 0: -0.6726123211877055\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -0.014527401356023994\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 0: -0.33630616059385277\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -0.00036808415727477726\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 2: -0.005260911351213704\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -0.00018404207863738863\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 0: -0.16815308029692638\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -9.202103931869432e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 1: 0.35366028323983933\n",
      "Debug: Before Update - Q_value Right for state (1, 6, 0, 1) and action 2: -0.9800206564959677\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 2: -0.002630455675606852\n",
      "Debug: Before Update - Q_value Right for state (1, 6, 0, 1) and action 1: -0.4184322775321425\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 2: -0.001315227837803426\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -0.007263700678011997\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 0: -0.08407654014846319\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 2: -0.005447923750915283\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 1: 0.17683014161991967\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -4.601051965934716e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 1: 0.08841507080995983\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 2: -0.0027239618754576417\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 1: 0.04420753540497992\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -2.300525982967358e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 1: 0.02210376770248996\n",
      "Debug: Before Update - Q_value Right for state (1, 6, 0, 1) and action 2: -0.49001032824798385\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 1) and action 2: 0.20325183808702962\n",
      "Debug: Before Update - Q_value Right for state (1, 6, 0, 1) and action 1: -0.20921613876607126\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 1) and action 1: 0.006916331973815026\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -1.150262991483679e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 1) and action 0: 0.08375814807478688\n",
      "Debug: Before Update - Q_value Right for state (1, 6, 0, 1) and action 1: -0.10460806938303563\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 1) and action 0: 0.04187907403739344\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -0.0036318503390059985\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 0: -0.042038270074231596\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -0.0018159251695029992\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 0: -0.021019135037115798\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -0.0009079625847514996\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 1: 0.01105188385124498\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -5.751314957418395e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 0: -0.010509567518557899\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -2.8756574787091974e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 2: -0.000657613918901713\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -0.0004539812923757498\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 1: 0.8470810129877233\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 1: -0.24363055733507055\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 1: 0.42354050649386166\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 1: -0.12181527866753528\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 0: -0.9344301794268706\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -0.008204219129073955\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 0: -0.4672150897134353\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 2: 0.008337502056411428\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 1: 0.21177025324693083\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -0.0041021095645369775\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 2: -0.2782410999814673\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -0.0020510547822684888\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 2: -0.13912054999073364\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -0.0010255273911342444\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 2: -0.06956027499536682\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -0.0005127636955671222\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 0: -0.23360754485671764\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 0: 0.0046655291769600316\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 2: -0.03478013749768341\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 1: 0.024731393642216715\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 2: -0.017390068748841706\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 2: 0.013856338917801012\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 1: 0.10588512662346541\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 1: 0.012365696821108357\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 2: -0.008695034374420853\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 2: 0.004168751028205714\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 2: -0.004347517187210426\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -0.0002563818477835611\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 2: -0.002173758593605213\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 1: 0.006182848410554179\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 2: -0.0010868792968026066\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 2: 0.002084375514102857\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 2: -0.0005434396484013033\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -0.00012819092389178055\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 2: -0.00027171982420065165\n",
      "Debug: Before Update - Q_value Right for state (1, 7, 0, 0) and action 1: 0.0030914242052770893\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 0: -0.11680377242835882\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 1: -0.06090763933376764\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 2: -0.00013585991210032582\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 2: 0.0010421877570514285\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 2: -6.792995605016291e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 1: -0.03045381966688382\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 1: 0.05294256331173271\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 1: -0.01522690983344191\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 2: -3.3964978025081456e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -6.409546194589027e-05\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 2: -1.6982489012540728e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 2: 0.0005210938785257142\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 7, 0, 0) and action 1: 0.026471281655866354\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -3.204773097294514e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 8, 1, 0) and action 0: -0.10919681394065583\n",
      "Debug: Before Update - Q_value Right for state (2, 8, 1, 0) and action 2: -0.5067727906972035\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 1, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: -1, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 3, 1) and action 0: 0.4383891476671381\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 3, 1) and action 0: 0.11970048709848657\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 1.595487282484734e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 4.49185453395798e-05\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 7.97743641242367e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 2.24592726697899e-05\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -2.2636836494669286e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -1.4870848615431654e-05\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 3.988718206211835e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 7.215978801427196e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -1.1318418247334643e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -7.435424307715827e-06\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 1.9943591031059176e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 3.607989400713598e-06\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 9.971795515529588e-07\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 1.803994700356799e-06\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -5.6592091236673215e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 1.122963633489495e-05\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -2.8296045618336607e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 5.614818167447475e-06\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -1.4148022809168304e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -3.7177121538579134e-06\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 1: 0.5063619026585107\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 9.019973501783995e-07\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 1: 0.25318095132925533\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 4.5099867508919973e-07\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 1: 0.12659047566462767\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -1.8588560769289567e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 1: 0.06329523783231383\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -9.294280384644784e-07\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 1: 0.03164761891615692\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -4.647140192322392e-07\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 1: 0.01582380945807846\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 2.2549933754459986e-07\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 4, 2, 1) and action 2: -0.4148809859759903\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -2.323570096161196e-07\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 4, 2, 1) and action 0: 0.8623580804577005\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 1.1274966877229993e-07\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 0: 0.8148645431778143\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 5.6374834386149966e-08\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 1: 0.00791190472903923\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 2.8074090837237376e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 2: -0.26093966466168883\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -1.161785048080598e-07\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 0: 0.40743227158890716\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 2.8187417193074983e-08\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 0: 0.20371613579445358\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 1.4093708596537492e-08\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 1: 0.003955952364519615\n",
      "Debug: Before Update - Q_value Right for state (3, 4, 2, 1) and action 2: -0.8430538980421602\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 2, 1) and action 2: 0.04367763902782884\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 2, 1) and action 1: -0.7953145373214328\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 0.007268273256684764\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 1: -0.008649564460425425\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 0.003634136628342382\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -0.0045643916454113555\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 0.00330769079565707\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -0.0022821958227056778\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -0.003301749400819523\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -0.0011410979113528389\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -0.0016508747004097615\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -1.7821107607781902e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -0.0008254373502048808\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -0.0005705489556764194\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 0.001817068314171191\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 0.0005042500058212015\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -0.0004127186751024404\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 0.00025212500291060076\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -0.0002063593375512202\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -8.910553803890951e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 5, 1, 1) and action 2: -0.6410949155171433\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 8.126256984727115e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 5, 1, 1) and action 0: -0.9827550109500867\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -4.4552769019454754e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 0.0009085341570855955\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 4.063128492363557e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 0.001653845397828535\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -2.2276384509727377e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -0.0001031796687756101\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 2: -0.052702670337477775\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 0.0008269226989142675\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -0.0002852744778382097\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 0.00045426707854279776\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 0.00012606250145530038\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -5.158983438780505e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 2.0315642461817786e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 0.00041346134945713375\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 1.0157821230908893e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -2.5794917193902524e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -1.1138192254863689e-06\n",
      "Debug: Before Update - Q_value Left for state (4, 5, 1, 1) and action 1: 0.2401047213580485\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 5.078910615454447e-07\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 5, 1, 1) and action 0: -0.49137750547504333\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 6.303125072765019e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 5, 1, 1) and action 1: 0.12005236067902425\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 3.1515625363825095e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 5, 1, 1) and action 2: -0.32054745775857163\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -5.569096127431844e-07\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 5, 1, 1) and action 1: 0.060026180339512125\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -2.784548063715922e-07\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 1, 1) and action 1: -0.563115538228772\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 1, 1) and action 1: -0.3334052302689594\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 0: -0.044227090794890955\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 2: 0.2142520368910607\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 1: -0.31651111402109766\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 1: 0.8304997293856877\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 1: -0.15825555701054883\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 0: -0.06843186891593345\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 2: -0.6538992223743898\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 2: 0.10712601844553035\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 1: -0.07912777850527442\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 0: -0.034215934457966724\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 0: -0.022113545397445478\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -1.4378287393545987e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 2: -0.3269496111871949\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -0.0002269906461878749\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 1: -0.03956388925263721\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -7.189143696772993e-07\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 0: -0.011056772698722739\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -0.00011349532309393745\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 1: -0.019781944626318604\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -5.6747661546968726e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 2: -0.16347480559359745\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 0: -0.017107967228983362\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 2: -0.08173740279679872\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 2: -0.0013619809377288209\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 0: -0.005528386349361369\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -2.8373830773484363e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 1: -0.009890972313159302\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 1: 0.41524986469284386\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 2: -0.04086870139839936\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 0: -0.008553983614491681\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 1: -0.004945486156579651\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 1: 0.20762493234642193\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 0: -0.0027641931746806847\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 1: 0.10381246617321097\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 0: -0.0013820965873403424\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 2: 0.053563009222765176\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 0: -0.0006910482936701712\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 1: 0.05190623308660548\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 2: -0.02043435069919968\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 2: 0.026781504611382588\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 0: -0.0003455241468350856\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 0: -0.0042769918072458404\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 0: -0.0001727620734175428\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 1: 0.02595311654330274\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 2: -0.01021717534959984\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 2: 0.013390752305691294\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 6, 0, 1) and action 2: -0.00510858767479992\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 1: 0.01297655827165137\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 2: 0.49890712023822625\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 2: -0.026779336309589175\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 1: 0.40170114026940973\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 1: -0.839414913937087\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 0: 0.6815166185633257\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 2: -0.013389668154794587\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 0: 0.34075830928166284\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 1: -0.4197074569685435\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 1: 0.20085057013470486\n",
      "Debug: Before Update - Q_value Right for state (4, 7, 0, 0) and action 1: -0.9502758709235846\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 2: 0.24945356011911313\n",
      "Debug: Before Update - Q_value Right for state (4, 7, 0, 0) and action 0: -0.5294560836183411\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 2: 0.12472678005955656\n",
      "Debug: Before Update - Q_value Right for state (4, 7, 0, 0) and action 2: 0.9378094654400031\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 1: 0.10042528506735243\n",
      "Debug: Before Update - Q_value Right for state (4, 7, 0, 0) and action 1: -0.4751379354617923\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 0: 0.17037915464083142\n",
      "Debug: Before Update - Q_value Right for state (4, 7, 0, 0) and action 1: -0.23756896773089614\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 0: 0.08518957732041571\n",
      "Debug: Before Update - Q_value Right for state (4, 7, 0, 0) and action 2: 0.46890473272000155\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 2: 0.06236339002977828\n",
      "Debug: Before Update - Q_value Right for state (4, 7, 0, 0) and action 0: -0.26472804180917053\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 1: 0.050212642533676216\n",
      "Debug: Before Update - Q_value Right for state (4, 7, 0, 0) and action 2: 0.23445236636000077\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 2: 0.03118169501488914\n",
      "Debug: Before Update - Q_value Right for state (4, 7, 0, 0) and action 0: -0.13236402090458527\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 1: 0.025106321266838108\n",
      "Debug: Before Update - Q_value Right for state (4, 7, 0, 0) and action 1: -0.11878448386544807\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 1: 0.012553160633419054\n",
      "Debug: Before Update - Q_value Right for state (4, 7, 0, 0) and action 0: -0.06618201045229263\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 1: 0.006276580316709527\n",
      "Debug: Before Update - Q_value Right for state (4, 7, 0, 0) and action 2: 0.11722618318000039\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 2: 0.01559084750744457\n",
      "Debug: Before Update - Q_value Right for state (4, 7, 0, 0) and action 0: -0.03309100522614632\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 0: 0.042594788660207855\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 0: -0.41249200962195687\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 2: 0.007795423753722285\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 0: -0.20624600481097843\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 1: 0.0031382901583547635\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 1: -0.20985372848427175\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 1: 0.0015691450791773818\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 2: -0.006694834077397294\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 1: 0.0007845725395886909\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 0: -0.10312300240548922\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 2: 0.0038977118768611426\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 0: -0.05156150120274461\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 0: 0.021297394330103928\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 2: -0.003347417038698647\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 7, 0, 0) and action 2: 0.0019488559384305713\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 1: -0.10492686424213588\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 8, 1, 0) and action 0: -0.30565120234638\n",
      "Debug: Before Update - Q_value Right for state (3, 8, 1, 0) and action 2: -0.5081338070189227\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 1, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: -1, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 3, 3) and action 1: -0.17511453307161196\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 3, 3) and action 1: 0.4857355752712984\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 2: 0.8102020245953283\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 0: -0.5443213801430222\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 2: 0.40510101229766415\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 2: -0.17233659185028727\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 2: 0.20255050614883208\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 1: -0.45410239855897827\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 2: 0.10127525307441604\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 0: -0.2721606900715111\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 0: 0.8263355932995147\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 0: -0.13608034503575556\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 1: -0.6039931517231008\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 1: -0.22705119927948914\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 2: 0.05063762653720802\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 1: -0.11352559963974457\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 1: -0.3019965758615504\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 1: -0.056762799819872284\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 2: 0.02531881326860401\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 0: -0.06804017251787778\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 0: 0.41316779664975734\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 0: -0.03402008625893889\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 0: 0.20658389832487867\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 1: -0.028381399909936142\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 1: -0.1509982879307752\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 1: -0.014190699954968071\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 2: 0.012659406634302005\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 2: -0.08616829592514363\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 1: -0.0754991439653876\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 2: -0.04308414796257182\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 2: 0.006329703317151002\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 2: -0.02154207398128591\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 2: 0.003164851658575501\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 0: -0.017010043129469445\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 1: -0.0377495719826938\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 0: -0.008505021564734722\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 2: 0.0015824258292877506\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 2: -0.010771036990642954\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 2: 0.0007912129146438753\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 2: -0.005385518495321477\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 2: 0.00039560645732193765\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 2: -0.0026927592476607386\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 1: -0.0188747859913469\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 0: -0.004252510782367361\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 2, 3) and action 0: -0.13739408543143394\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 1: -0.0070953499774840355\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 2: 0.00019780322866096883\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 1: -0.0035476749887420177\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 3) and action 1: -0.00943739299567345\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 2: -0.0013463796238303693\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 2, 3) and action 0: -0.06869704271571697\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 2, 3) and action 2: -0.0006731898119151846\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 2, 1, 3) and action 1: 0.7326385006640428\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 1, 3) and action 1: 0.25247908474678193\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 2: -0.6362925381060893\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 1, 3) and action 0: 0.727735119718669\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 1: 0.07706092659133112\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 1, 3) and action 1: 0.12623954237339097\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 1: 0.03853046329566556\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 1, 3) and action 2: 0.915976201205734\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 0: 0.12908906170440115\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 1, 3) and action 1: 0.06311977118669548\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 2: -0.31814626905304466\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 1, 3) and action 1: 0.03155988559334774\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 0: 0.06454453085220058\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 2: -0.4213151940556108\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 1: 0.01926523164783278\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 1: -0.9570519609396579\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 1: 0.00963261582391639\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 1: -0.47852598046982897\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 0: 0.03227226542610029\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 1: -0.23926299023491449\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 0: 0.016136132713050144\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 0: 0.5483164185432887\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 1: 0.004816307911958195\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 0: 0.27415820927164436\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 1: 0.0024081539559790976\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 1: -0.11963149511745724\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 2: -0.15907313452652233\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 0: 0.13707910463582218\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 2: -0.07953656726326117\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 2: -0.2106575970278054\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 0: 0.008068066356525072\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 2: -0.1053287985139027\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 1: 0.0012040769779895488\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 0: 0.06853955231791109\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 2: -0.03976828363163058\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 0: 0.034269776158955545\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 2: -0.01988414181581529\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 1, 3) and action 1: 0.01577994279667387\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 0: 0.004034033178262536\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 0: 0.017134888079477772\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 1: 0.0006020384889947744\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 1, 3) and action 1: 0.007889971398336935\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 2: -0.009942070907907646\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 1: -0.05981574755872862\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 1: 0.0003010192444973872\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 1: -0.02990787377936431\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 1: 0.0001505096222486936\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 2: -0.05266439925695135\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 1, 3) and action 0: 0.002017016589131268\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 1, 3) and action 2: -0.026332199628475675\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 1, 0, 3) and action 2: 0.9188601836705528\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 0: 0.8924366067568859\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 1, 0, 3) and action 1: -0.56676816918294\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 1: -0.5179900724650159\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 1, 0, 3) and action 1: -0.28338408459147\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 2: -0.9612430596742334\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (3, 1, 0, 3) and action 1: -0.141692042295735\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 0: 0.4462183033784429\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 1: -0.41266308918472316\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 1: -0.25899503623250797\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 0: -0.3257468712999685\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 2: -0.4806215298371167\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 2: -0.11971076500791011\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 0: 0.22310915168922146\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 2: -0.05985538250395506\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 2: -0.24031076491855835\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 1: -0.20633154459236158\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 1: -0.12949751811625398\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 2: -0.02992769125197753\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 1: -0.06474875905812699\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 1: -0.10316577229618079\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 1: -0.032374379529063496\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 1: -0.051582886148090396\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 1: -0.016187189764531748\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 1: -0.025791443074045198\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 1: -0.008093594882265874\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 0: -0.16287343564998424\n",
      "Debug: Before Update - Q_value Right for state (4, 1, 0, 3) and action 1: 0.3005271218740584\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 1: -0.012895721537022599\n",
      "Debug: Before Update - Q_value Right for state (4, 1, 0, 3) and action 0: 0.006248852371800062\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 0: -0.08143671782499212\n",
      "Debug: Before Update - Q_value Right for state (4, 1, 0, 3) and action 0: 0.003124426185900031\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 1: -0.0064478607685112994\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 2: -0.12015538245927918\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 2: -0.014963845625988764\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 2: -0.06007769122963959\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 2: -0.007481922812994382\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 0, 3) and action 1: -0.004046797441132937\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 0: -0.04071835891249606\n",
      "Debug: Before Update - Q_value Right for state (4, 1, 0, 3) and action 1: 0.1502635609370292\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 2: -0.003740961406497191\n",
      "Debug: Before Update - Q_value Right for state (4, 1, 0, 3) and action 2: 0.8019789163559004\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 1: -0.0032239303842556497\n",
      "Debug: Before Update - Q_value Right for state (4, 1, 0, 3) and action 1: 0.0751317804685146\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 2: -0.0018704807032485955\n",
      "Debug: Before Update - Q_value Right for state (4, 1, 0, 3) and action 2: 0.4009894581779502\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 3) and action 2: -0.0009352403516242978\n",
      "Debug: Before Update - Q_value Right for state (4, 1, 0, 3) and action 1: 0.0375658902342573\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 0, 2) and action 2: -0.25777371504435287\n",
      "Debug: Before Update - Q_value Right for state (4, 1, 0, 2) and action 2: -0.04775087859837002\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 0, 2) and action 1: -0.26993230134684465\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 2: -0.26434104942432834\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 0, 2) and action 2: -0.11020149540916058\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 0: -0.8172046929209353\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 0, 2) and action 1: -0.13496615067342232\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 0: -0.40860234646046767\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 0, 2) and action 1: -0.06748307533671116\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 2: -0.13217052471216417\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 0, 2) and action 2: 0.20131007515942945\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 0: -0.20430117323023383\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 0, 2) and action 1: -0.1729762201334033\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 0: -0.10215058661511692\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 0, 2) and action 1: -0.08648811006670165\n",
      "Debug: Before Update - Q_value Right for state (3, 0, 0, 2) and action 1: 0.2391616104263914\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 0, 2) and action 1: -0.043244055033350826\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 0: -0.05107529330755846\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 0, 2) and action 1: -0.021622027516675413\n",
      "Debug: Before Update - Q_value Right for state (3, 0, 0, 2) and action 1: 0.1195808052131957\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 0, 2) and action 0: 0.2788431291174702\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 2: -0.06608526235608209\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 0, 2) and action 1: -0.03374153766835558\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 0: -0.02553764665377923\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 0, 2) and action 0: 0.1394215645587351\n",
      "Debug: Before Update - Q_value Right for state (3, 0, 0, 2) and action 1: 0.05979040260659785\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 0, 2) and action 1: -0.01687076883417779\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 2: -0.03304263117804104\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 0, 2) and action 2: 0.10065503757971472\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 0: -0.012768823326889615\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 0, 2) and action 0: 0.06971078227936756\n",
      "Debug: Before Update - Q_value Right for state (3, 0, 0, 2) and action 1: 0.029895201303298924\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 0, 2) and action 1: -0.008435384417088895\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 1: -0.4372594443427924\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 0, 2) and action 0: 0.03485539113968378\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 1: -0.2186297221713962\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 0, 2) and action 0: 0.6502230405660319\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 0: -0.006384411663444807\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 0, 2) and action 1: -0.004217692208544448\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 1: -0.1093148610856981\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 0, 2) and action 2: -0.05510074770458029\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 1: -0.05465743054284905\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 0, 2) and action 2: -0.027550373852290144\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 0: -0.0031922058317224037\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 0, 2) and action 1: -0.002108846104272224\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 0: -0.0015961029158612018\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 0, 2) and action 2: 0.05032751878985736\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 2: -0.01652131558902052\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 0, 2) and action 0: 0.01742769556984189\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 0, 2) and action 1: -0.027328715271424525\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 1, 2) and action 0: 0.04603436351331891\n",
      "Debug: Before Update - Q_value Right for state (4, 0, 1, 2) and action 1: -0.8653587146438309\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: -1, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 1, Best Next Action Right: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (2, 4, 3, 2) and action 0: -0.2943907034860238\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 3, 2) and action 2: -0.47673492938797857\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 3, 2) and action 1: 0.5908018213554207\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 1: 0.21812846874392844\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 3, 2) and action 1: 0.29540091067771035\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 0: -0.37572312187999035\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 3, 2) and action 1: 0.14770045533885517\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 2: 0.5929193434702376\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 3, 2) and action 2: -0.9106322320342053\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 0: -0.18786156093999518\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 3, 2) and action 2: -0.45531611601710265\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 2: 0.2964596717351188\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 3, 2) and action 1: 0.07385022766942759\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 2: 0.1482298358675594\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 3, 2) and action 2: -0.22765805800855132\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 1: 0.10906423437196422\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 3, 2) and action 1: 0.036925113834713794\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 0: -0.09393078046999759\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 1: -0.07674931893833259\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 2: 0.0741149179337797\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 2: -0.47679929677067423\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 0: -0.046965390234998794\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 0: -0.6752061842011312\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 0: -0.023482695117499397\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 1: -0.038374659469166295\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 0: -0.011741347558749698\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 0: -0.3376030921005656\n",
      "Debug: Before Update - Q_value Right for state (1, 3, 3, 2) and action 1: 0.5006860503347581\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 1: -0.019187329734583147\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 0: -0.005870673779374849\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 2: -0.23839964838533712\n",
      "Debug: Before Update - Q_value Right for state (1, 3, 3, 2) and action 2: 0.38376453733189364\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 2: -0.11919982419266856\n",
      "Debug: Before Update - Q_value Right for state (1, 3, 3, 2) and action 0: -0.9005678510616679\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 1: -0.009593664867291574\n",
      "Debug: Before Update - Q_value Right for state (1, 3, 3, 2) and action 2: 0.19188226866594682\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 1: -0.004796832433645787\n",
      "Debug: Before Update - Q_value Right for state (1, 3, 3, 2) and action 1: 0.25034302516737905\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 2: -0.05959991209633428\n",
      "Debug: Before Update - Q_value Right for state (1, 3, 3, 2) and action 2: 0.09594113433297341\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 2: -0.02979995604816714\n",
      "Debug: Before Update - Q_value Right for state (1, 3, 3, 2) and action 1: 0.12517151258368953\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 1: -0.0023984162168228934\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 2: 0.03705745896688985\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 2: -0.01489997802408357\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 0: -0.0029353368896874246\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 2: -0.007449989012041785\n",
      "Debug: Before Update - Q_value Right for state (1, 3, 3, 2) and action 1: 0.06258575629184476\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 2) and action 1: -0.0011992081084114467\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 3, 2) and action 1: 0.05453211718598211\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 4, 2) and action 2: -0.032319721959658265\n",
      "Debug: Before Update - Q_value Right for state (2, 3, 4, 2) and action 2: -0.9434510216847409\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 4, 2) and action 1: -0.8747899974507078\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 1: 0.24836720502098975\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 2) and action 2: 0.8401328563915325\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 2: 0.26175273600332605\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 2) and action 0: 0.6736103580113364\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 1: 0.12418360251049487\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 4, 2) and action 2: -0.3859792232860455\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 0: -0.4297866732870781\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 4, 2) and action 2: -0.19298961164302275\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 2: 0.13087636800166302\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 4, 2) and action 2: -0.09649480582151138\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 0: -0.21489333664353905\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 4, 2) and action 2: -0.04824740291075569\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 2: 0.06543818400083151\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 4, 2) and action 2: -0.024123701455377844\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 1: 0.062091801255247436\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 4, 2) and action 1: -0.4373949987253539\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 2: 0.032719092000415756\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 2) and action 1: -0.797159537442987\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 2: 0.016359546000207878\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 2) and action 0: 0.3368051790056682\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 0: -0.10744666832176952\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 2) and action 0: 0.1684025895028341\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 0: -0.05372333416088476\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 4, 2) and action 1: -0.21869749936267696\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 1: 0.031045900627623718\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 2) and action 0: 0.08420129475141705\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 2: 0.008179773000103939\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 4, 2) and action 0: 0.5902375962908217\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 1: 0.015522950313811859\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 4, 2) and action 2: -0.012061850727688922\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 0: -0.02686166708044238\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 4, 2) and action 2: -0.006030925363844461\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 1: 0.0077614751569059295\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 4, 2) and action 2: -0.0030154626819222305\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 1: 0.0038807375784529648\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 4, 2) and action 1: -0.10934874968133848\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 2: 0.0040898865000519695\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 4, 2) and action 1: -0.05467437484066924\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 2: 0.0020449432500259847\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 2) and action 1: -0.3985797687214935\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 2: 0.0010224716250129924\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 2) and action 2: 0.42006642819576623\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 1: 0.0019403687892264824\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 2) and action 1: -0.19928988436074674\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 0: -0.01343083354022119\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 2) and action 2: 0.21003321409788311\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 4, 2) and action 1: 0.0009701843946132412\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 5, 2) and action 2: -0.05556410528784039\n",
      "Debug: Before Update - Q_value Right for state (2, 2, 5, 2) and action 2: 0.6460781924048313\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 2: 0.27515674288310676\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 5, 2) and action 1: -0.16576642321528756\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 1: -0.9118676617370933\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 5, 2) and action 1: -0.08288321160764378\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 1: -0.45593383086854666\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 5, 2) and action 2: -0.7395135397110502\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 0: -0.6103444126894861\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 5, 2) and action 1: -0.04144160580382189\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 1: -0.22796691543427333\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 2) and action 2: 0.8328445689754322\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 0: -0.30517220634474307\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 2) and action 0: 0.13334661623783872\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 0: -0.15258610317237153\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 5, 2) and action 2: -0.3697567698555251\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 1: -0.11398345771713667\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 5, 2) and action 1: -0.020720802901910945\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 1: -0.05699172885856833\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 2) and action 1: 0.1947139358359229\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 0: -0.07629305158618577\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 2) and action 0: 0.06667330811891936\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 2: 0.13757837144155338\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 2) and action 2: 0.4164222844877161\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 0: -0.038146525793092884\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 2) and action 1: 0.09735696791796145\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 2: 0.06878918572077669\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 2) and action 0: 0.03333665405945968\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 1: -0.028495864429284166\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 2) and action 0: 0.01666832702972984\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 1: -0.014247932214642083\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 5, 2) and action 0: 0.3872713454086074\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 0: -0.019073262896546442\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 5, 2) and action 1: -0.010360401450955473\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 0: -0.009536631448273221\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 5, 2) and action 1: -0.005180200725477736\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 1: -0.007123966107321042\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 2) and action 0: 0.00833416351486492\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 1: -0.003561983053660521\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 5, 2) and action 0: 0.1936356727043037\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 1: -0.0017809915268302604\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 5, 2) and action 2: -0.18487838492776254\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 1: -0.0008904957634151302\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 5, 2) and action 1: -0.002590100362738868\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 0: -0.0047683157241366105\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 5, 2) and action 2: -0.09243919246388127\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 2: 0.034394592860388346\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 5, 2) and action 2: -0.046219596231940635\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 2) and action 2: 0.017197296430194173\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 5, 2) and action 2: -0.023109798115970318\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 6, 3) and action 0: -0.7218307558606618\n",
      "Debug: Before Update - Q_value Right for state (2, 1, 6, 3) and action 0: 0.33881556319486683\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (4, 0, 5, 3) and action 0: 0.8478990789049077\n",
      "Debug: Before Update - Q_value Right for state (2, 0, 5, 3) and action 1: -0.9905876620657086\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 5, 3) and action 2: 0.3691962478764492\n",
      "Debug: Before Update - Q_value Right for state (2, 0, 5, 3) and action 1: -0.4952938310328543\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 5, 3) and action 1: 0.33066210272533136\n",
      "Debug: Before Update - Q_value Right for state (3, 0, 5, 3) and action 2: 0.3131026249131055\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 5, 3) and action 1: 0.16533105136266568\n",
      "Debug: Before Update - Q_value Right for state (3, 0, 5, 3) and action 0: -0.7831093663846658\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 5, 3) and action 1: 0.08266552568133284\n",
      "Debug: Before Update - Q_value Right for state (2, 0, 5, 3) and action 1: -0.24764691551642715\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 5, 3) and action 2: 0.1845981239382246\n",
      "Debug: Before Update - Q_value Right for state (3, 0, 5, 3) and action 1: -0.8619662499408385\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 0, 5, 3) and action 1: 0.04133276284066642\n",
      "Debug: Before Update - Q_value Right for state (3, 0, 5, 3) and action 2: 0.15655131245655274\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 1, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 5, 1) and action 1: 0.5138775870916461\n",
      "Debug: Before Update - Q_value Right for state (3, 0, 5, 1) and action 1: -0.07153324517462156\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 5, 1) and action 1: 0.25693879354582305\n",
      "Debug: Before Update - Q_value Right for state (3, 0, 5, 1) and action 2: -0.49098175850276893\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 5, 1) and action 2: 0.1579474014789184\n",
      "Debug: Before Update - Q_value Right for state (3, 0, 5, 1) and action 2: -0.24549087925138446\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 5, 1) and action 1: 0.12846939677291153\n",
      "Debug: Before Update - Q_value Right for state (3, 0, 5, 1) and action 2: -0.12274543962569223\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 5, 1) and action 1: 0.06423469838645576\n",
      "Debug: Before Update - Q_value Right for state (3, 0, 5, 1) and action 0: -0.04247342756982908\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 5, 1) and action 2: 0.0789737007394592\n",
      "Debug: Before Update - Q_value Right for state (3, 0, 5, 1) and action 2: -0.061372719812846116\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 0, 5, 1) and action 0: -0.5053940674910156\n",
      "Debug: Before Update - Q_value Right for state (3, 0, 5, 1) and action 1: -0.03576662258731078\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 1) and action 1: 0.043825973417870534\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 1) and action 1: 0.5271186572680586\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (5, 1, 5, 1) and action 0: 0.03396304677372575\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 1) and action 0: -0.07723120420248963\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 1) and action 0: 0.2581687647732862\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 1) and action 1: 0.2635593286340293\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 1) and action 2: -0.002244436935321392\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 1) and action 2: -0.5487992680132538\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 1) and action 0: 0.1290843823866431\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 1) and action 1: 0.13177966431701466\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 1) and action 0: 0.06454219119332155\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 1) and action 2: -0.2743996340066269\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 1) and action 2: -0.001122218467660696\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 1) and action 1: 0.06588983215850733\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 1) and action 2: -0.000561109233830348\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 1) and action 2: -0.13719981700331346\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 1) and action 0: 0.032271095596660776\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 1) and action 0: -0.03861560210124482\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 1) and action 0: 0.016135547798330388\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 1) and action 0: -0.01930780105062241\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 5, 1) and action 0: 0.008067773899165194\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 5, 1) and action 0: -0.009653900525311204\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 4, 1) and action 2: 0.7529486539814294\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 4, 1) and action 0: 0.6791994348891972\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 4, 1) and action 0: -0.4317876104261722\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 4, 1) and action 1: -0.2825595761089281\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 1, 4, 1) and action 1: -0.1258020411102838\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 4, 1) and action 2: 0.6880046307853134\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 4, 1) and action 1: -0.4346567542660771\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 4, 1) and action 0: 0.3395997174445986\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 4, 1) and action 1: -0.21732837713303854\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 4, 1) and action 1: -0.14127978805446406\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 4, 1) and action 2: 0.3764743269907147\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 4, 1) and action 1: -0.07063989402723203\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 4, 1) and action 1: -0.10866418856651927\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 4, 1) and action 2: 0.3440023153926567\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 4, 1) and action 2: 0.18823716349535735\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 4, 1) and action 1: -0.035319947013616015\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 4, 1) and action 2: 0.09411858174767868\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 4, 1) and action 0: 0.1697998587222993\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 4, 1) and action 2: 0.04705929087383934\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 4, 1) and action 1: -0.017659973506808008\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (4, 1, 4, 1) and action 1: -0.054332094283259635\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 4, 1) and action 1: -0.008829986753404004\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 4, 1) and action 0: -0.2158938052130861\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 4, 1) and action 1: -0.004414993376702002\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 4, 1) and action 2: 0.02352964543691967\n",
      "Debug: Before Update - Q_value Right for state (4, 1, 4, 1) and action 0: -0.019894057493961004\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 1, 4, 1) and action 1: -0.027166047141629818\n",
      "Debug: Before Update - Q_value Right for state (3, 1, 4, 1) and action 0: 0.08489992936114965\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 1) and action 0: 0.11646956703959055\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 4, 1) and action 1: 0.00772921856313169\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 1) and action 2: 0.3251384661590344\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 4, 1) and action 0: -0.0024417093912527665\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 1) and action 1: 0.9886711453483088\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 4, 1) and action 0: -0.0012208546956263833\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 1) and action 2: 0.1625692330795172\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 4, 1) and action 1: 0.003864609281565845\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 1) and action 1: 0.4943355726741544\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 4, 1) and action 2: 0.5512441047488419\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 1) and action 2: 0.0812846165397586\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 4, 1) and action 1: 0.0019323046407829225\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 1) and action 0: 0.058234783519795275\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 4, 1) and action 2: 0.27562205237442094\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 1) and action 1: 0.2471677863370772\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 4, 1) and action 0: -0.0006104273478131916\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 1) and action 2: 0.0406423082698793\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 4, 1) and action 2: 0.13781102618721047\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 1) and action 2: 0.02032115413493965\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 4, 1) and action 1: 0.0009661523203914613\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 4, 1) and action 2: 0.010160577067469825\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 4, 1) and action 1: 0.00048307616019573063\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 3, 1) and action 0: -0.27438885770444466\n",
      "Debug: Before Update - Q_value Right for state (4, 2, 3, 1) and action 2: 0.5653564765732626\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 3, 1) and action 0: -0.13719442885222233\n",
      "Debug: Before Update - Q_value Right for state (4, 2, 3, 1) and action 2: 0.2826782382866313\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 3, 1) and action 2: -0.14535588389639176\n",
      "Debug: Before Update - Q_value Right for state (4, 2, 3, 1) and action 2: 0.14133911914331565\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 3, 1) and action 2: -0.07267794194819588\n",
      "Debug: Before Update - Q_value Right for state (4, 2, 3, 1) and action 0: -0.7411248918853715\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 3, 1) and action 2: -0.03633897097409794\n",
      "Debug: Before Update - Q_value Right for state (3, 2, 3, 1) and action 1: -0.6839083405725277\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 3, 1) and action 2: -0.01816948548704897\n",
      "Debug: Before Update - Q_value Right for state (4, 2, 3, 1) and action 1: -0.1676136670217736\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 3, 1) and action 2: -0.009084742743524485\n",
      "Debug: Before Update - Q_value Right for state (4, 2, 3, 1) and action 0: -0.3705624459426857\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 3, 1) and action 0: -0.06859721442611116\n",
      "Debug: Before Update - Q_value Right for state (4, 2, 3, 1) and action 1: -0.0838068335108868\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 3, 1) and action 0: -0.03429860721305558\n",
      "Debug: Before Update - Q_value Right for state (4, 2, 3, 1) and action 2: 0.07066955957165783\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 3, 1) and action 0: -0.01714930360652779\n",
      "Debug: Before Update - Q_value Right for state (4, 2, 3, 1) and action 1: -0.0419034167554434\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 2, 3, 1) and action 0: -0.008574651803263895\n",
      "Debug: Before Update - Q_value Right for state (4, 2, 3, 1) and action 1: -0.0209517083777217\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 3, 1) and action 0: -0.4426239159632721\n",
      "Debug: Before Update - Q_value Right for state (4, 2, 3, 1) and action 2: 0.03533477978582891\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 3, 1) and action 0: -0.22131195798163605\n",
      "Debug: Before Update - Q_value Right for state (4, 2, 3, 1) and action 1: -0.01047585418886085\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 2, 3, 1) and action 0: -0.11065597899081803\n",
      "Debug: Before Update - Q_value Right for state (4, 2, 3, 1) and action 2: 0.017667389892914456\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 1) and action 1: 0.4479059031097703\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 3, 1) and action 2: 0.35054342063449795\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 1) and action 2: -0.262421433452696\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 3, 1) and action 1: 0.6886658812501019\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 1) and action 1: 0.22395295155488515\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 3, 1) and action 2: 0.17527171031724897\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 1) and action 1: 0.11197647577744257\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 3, 1) and action 2: 0.08763585515862449\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 1) and action 0: 0.018349460114135185\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 3, 1) and action 1: 0.34433294062505093\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 1) and action 0: 0.009174730057067593\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 3, 1) and action 1: 0.17216647031252547\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 1) and action 0: 0.004587365028533796\n",
      "Debug: Before Update - Q_value Right for state (5, 3, 3, 1) and action 2: -0.7679456281606085\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 1) and action 2: -0.131210716726348\n",
      "Debug: Before Update - Q_value Right for state (5, 3, 3, 1) and action 1: 0.3127955817364827\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 1) and action 2: -0.065605358363174\n",
      "Debug: Before Update - Q_value Right for state (5, 3, 3, 1) and action 2: -0.38397281408030426\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 1) and action 0: 0.002293682514266898\n",
      "Debug: Before Update - Q_value Right for state (5, 3, 3, 1) and action 0: 0.42187579197524494\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 3, 1) and action 2: -0.032802679181587\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 3, 1) and action 2: 0.043817927579312244\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 2, 1) and action 0: -0.43230483882372184\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 2, 1) and action 0: 0.3952283803270684\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 3, 2, 1) and action 0: -0.21615241941186092\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 2, 1) and action 2: -0.35612894572383835\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 1) and action 0: 0.80742749437906\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 2, 1) and action 2: -0.17806447286191918\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 1) and action 0: 0.40371374718953\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 2, 1) and action 0: 0.1976141901635342\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 1) and action 2: 0.7809781652777241\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 2, 1) and action 2: -0.08903223643095959\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 1) and action 0: 0.201856873594765\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 2, 1) and action 0: 0.0988070950817671\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 1) and action 2: 0.39048908263886206\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 2, 1) and action 0: 0.04940354754088355\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 1) and action 1: 0.5809226821951485\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 2, 1) and action 2: -0.044516118215479794\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 1) and action 0: 0.1009284367973825\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 2, 1) and action 1: -0.7365590692286852\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 1) and action 0: 0.05046421839869125\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 2, 1) and action 0: 0.024701773770441776\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 1) and action 1: 0.29046134109757427\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 2, 1) and action 0: 0.012350886885220888\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 1) and action 2: 0.19524454131943103\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 2, 1) and action 2: -0.022258059107739897\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 1) and action 2: 0.09762227065971552\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 2, 1) and action 2: -0.011129029553869949\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 3, 2, 1) and action 0: 0.025232109199345626\n",
      "Debug: Before Update - Q_value Right for state (4, 3, 2, 1) and action 2: -0.005564514776934974\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 1.263388465670806e-05\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 2, 1) and action 1: -0.0383198648505747\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -7.074011404584152e-07\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 2, 1) and action 1: -0.01915993242528735\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -3.537005702292076e-07\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 2, 1) and action 2: -0.40292831063084433\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 4.985897757764794e-07\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 2, 1) and action 2: -0.20146415531542217\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -1.768502851146038e-07\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 2, 1) and action 2: -0.10073207765771108\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -8.84251425573019e-08\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 2, 1) and action 1: -0.009579966212643676\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 2.492948878882397e-07\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 2, 1) and action 1: -0.004789983106321838\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -4.421257127865095e-08\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 2, 1) and action 2: -0.05036603882885554\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 6.31694232835403e-06\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 2, 1) and action 2: -0.02518301941442777\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 0: 3.158471164177015e-06\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 2, 1) and action 1: -0.002394991553160919\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -2.2106285639325475e-08\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 2, 1) and action 0: 0.6363744489315017\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 1, 1) and action 0: -0.1358895449109807\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 1, 1) and action 0: 0.08217986610002748\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 1, 1) and action 0: -0.06794477245549035\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 1, 1) and action 0: 0.04108993305001374\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 1, 1) and action 1: -0.41216905996620556\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 1, 1) and action 2: 0.6999275421435285\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 1, 1) and action 1: -0.20608452998310278\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 1, 1) and action 1: -0.7197396292814731\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 1, 1) and action 2: -0.4704042217464621\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 1, 1) and action 0: 0.02054496652500687\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 1, 1) and action 0: -0.03397238622774518\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 1, 1) and action 0: 0.010272483262503435\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 1, 1) and action 0: -0.01698619311387259\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 1, 1) and action 0: 0.005136241631251717\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 1, 1) and action 0: -0.008493096556936294\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 1, 1) and action 2: 0.34996377107176424\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 1, 1) and action 0: -0.004246548278468147\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 1, 1) and action 2: 0.17498188553588212\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 1, 1) and action 0: -0.0021232741392340736\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 1, 1) and action 2: 0.08749094276794106\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 1, 1) and action 0: -0.0010616370696170368\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 1, 1) and action 1: -0.35986981464073653\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 4, 1, 1) and action 0: 0.22369016376861106\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 1, 1) and action 1: -0.17993490732036826\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 4, 1, 1) and action 1: -0.5968926186144881\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 1, 1) and action 2: 0.04374547138397053\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 4, 1, 1) and action 0: 0.11184508188430553\n",
      "Debug: Before Update - Q_value Right for state (4, 4, 1, 1) and action 2: 0.021872735691985265\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 0: 0.04887612833036328\n",
      "Debug: Before Update - Q_value Right for state (4, 5, 1, 1) and action 0: 0.27484261994404346\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 0: 0.02443806416518164\n",
      "Debug: Before Update - Q_value Right for state (4, 5, 1, 1) and action 0: 0.13742130997202173\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 1: -0.006956998244356333\n",
      "Debug: Before Update - Q_value Right for state (4, 5, 1, 1) and action 2: -0.9686153466821232\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 1: -0.0034784991221781664\n",
      "Debug: Before Update - Q_value Right for state (4, 5, 1, 1) and action 1: 0.3405578618849421\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 2: 0.0037362212071262724\n",
      "Debug: Before Update - Q_value Right for state (4, 5, 1, 1) and action 2: -0.4843076733410616\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 1: -0.0017392495610890832\n",
      "Debug: Before Update - Q_value Right for state (4, 5, 1, 1) and action 0: 0.06871065498601087\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 2: 0.0018681106035631362\n",
      "Debug: Before Update - Q_value Right for state (4, 5, 1, 1) and action 0: 0.03435532749300543\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 0: 0.01221903208259082\n",
      "Debug: Before Update - Q_value Right for state (4, 5, 1, 1) and action 2: -0.2421538366705308\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 0: 0.00610951604129541\n",
      "Debug: Before Update - Q_value Right for state (4, 5, 1, 1) and action 2: -0.1210769183352654\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 0: 0.003054758020647705\n",
      "Debug: Before Update - Q_value Right for state (4, 5, 1, 1) and action 1: 0.17027893094247104\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 1, 1) and action 0: 0.0015273790103238526\n",
      "Debug: Before Update - Q_value Right for state (4, 5, 1, 1) and action 0: 0.017177663746502717\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 0, 1) and action 2: 0.5498132876861874\n",
      "Debug: Before Update - Q_value Right for state (4, 5, 0, 1) and action 2: -0.17764856363123305\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 0, 1) and action 2: 0.2749066438430937\n",
      "Debug: Before Update - Q_value Right for state (4, 5, 0, 1) and action 0: 0.6383197641288363\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 0, 1) and action 0: 0.302798614123436\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 0, 1) and action 0: 0.29422054565789946\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 0, 1) and action 2: 0.13745332192154686\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 0, 1) and action 1: -0.4400327853836401\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 0, 1) and action 1: -0.8522285730942207\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 0, 1) and action 0: 0.14711027282894973\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 0, 1) and action 1: -0.42611428654711037\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 0, 1) and action 0: 0.07355513641447486\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 0, 1) and action 2: 0.06872666096077343\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 0, 1) and action 1: -0.22001639269182005\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 0, 1) and action 2: 0.034363330480386714\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 0, 1) and action 2: -0.3194128253573396\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 0, 1) and action 1: -0.21305714327355518\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 0, 1) and action 2: -0.1597064126786698\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 0, 1) and action 0: 0.151399307061718\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 0, 1) and action 0: 0.03677756820723743\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 0, 1) and action 0: 0.075699653530859\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 0, 1) and action 0: 0.018388784103618716\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 0, 1) and action 2: 0.017181665240193357\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 0, 1) and action 2: -0.0798532063393349\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 0, 1) and action 0: 0.0378498267654295\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 0, 1) and action 1: -0.11000819634591003\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 5, 0, 1) and action 1: -0.10652857163677759\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 0, 1) and action 2: -0.03992660316966745\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 1: 0.00552594192562249\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 0: -0.0021384959036229202\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 1: 0.002762970962811245\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 1: 0.006488279135825685\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 1: 0.0013814854814056224\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 0: -0.0010692479518114601\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 1: 0.0006907427407028112\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 1: 0.0032441395679128427\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 1) and action 1: 0.0003453713703514056\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 2: 0.006695376152845647\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 1) and action 2: 0.10162591904351481\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 1: 0.0016220697839564213\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 1) and action 2: 0.050812959521757406\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 0: -0.0005346239759057301\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 1) and action 2: 0.025406479760878703\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 0: -0.00026731198795286503\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 1) and action 2: 0.012703239880439351\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 2: 0.0033476880764228235\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 1) and action 2: 0.006351619940219676\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 1) and action 0: -0.00013365599397643251\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 0) and action 1: 0.39845673091277156\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 0) and action 2: 0.135423072706365\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 0) and action 0: 0.13304211151275758\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 0) and action 0: 0.16808619525150426\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 0) and action 2: -4.903722048599235e-05\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 0) and action 0: 0.08404309762575213\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 0) and action 0: 0.06652105575637879\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 0) and action 1: -0.5881224301401102\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 0) and action 2: 0.3039398610893551\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 0) and action 2: 0.0677115363531825\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 0) and action 2: 0.15196993054467756\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 0) and action 2: 0.03385576817659125\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 0) and action 2: 0.07598496527233878\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 0) and action 0: 0.042021548812876064\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (1, 6, 0, 0) and action 1: -0.9424886219648951\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 0) and action 1: -0.2940612150700551\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 0) and action 1: 0.19922836545638578\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 0) and action 2: 0.016927884088295625\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 0) and action 0: 0.033260527878189394\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 0) and action 0: 0.021010774406438032\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 0) and action 1: 0.09961418272819289\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 0) and action 1: -0.14703060753502756\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 0) and action 2: -2.4518610242996175e-05\n",
      "Debug: Before Update - Q_value Right for state (3, 6, 0, 0) and action 0: 0.010505387203219016\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 0) and action 2: -1.2259305121498087e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 0) and action 0: -0.7603800507835752\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 0) and action 2: -6.129652560749044e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 0) and action 2: -0.40203467946428706\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 6, 0, 0) and action 2: -3.064826280374522e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 0) and action 1: -0.07351530376751378\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 1: -4.724989558228983e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 2: 0.0002605469392628571\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 2: -0.0002927224747437465\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 1: -0.007613454916720955\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 1: -2.3624947791144914e-05\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 2: -0.0016737085193493234\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 0: -0.005942486729150473\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 1: -0.05246343212106794\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 2: -0.00014636123737187326\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 0: -0.025780750601372304\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 2: -7.318061868593663e-05\n",
      "Debug: Before Update - Q_value Right for state (3, 7, 0, 0) and action 0: -0.012890375300686152\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 1: -1.1812473895572457e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -1.602386548647257e-05\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 0: -0.0029712433645752365\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -8.011932743236284e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 2: -3.6590309342968315e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 0: -4.005966371618142e-06\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 0, 0) and action 1: -5.9062369477862284e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 0, 0) and action 2: 0.00013027346963142856\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 1, 0) and action 2: -0.5237174487810754\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 1, 0) and action 0: -0.7036404304023116\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 1, 0) and action 2: -0.2618587243905377\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 1, 0) and action 2: 0.07497792320856767\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 1, 0) and action 2: -0.13092936219526885\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 1, 0) and action 2: 0.03748896160428383\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 1, 0) and action 2: -0.06546468109763443\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 1, 0) and action 0: -0.3518202152011558\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 1, 0) and action 1: 0.1444172830725996\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 1, 0) and action 2: 0.018744480802141916\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 1, 0) and action 0: 0.6429736105692005\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 1, 0) and action 0: -0.1759101076005779\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 1, 0) and action 0: 0.3214868052846003\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 1, 0) and action 1: 0.6894842373802501\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 1, 0) and action 2: -0.03273234054881721\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 1, 0) and action 0: -0.08795505380028895\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 1, 0) and action 1: 0.0722086415362998\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 1, 0) and action 2: 0.009372240401070958\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 1, 0) and action 2: -0.016366170274408606\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 1, 0) and action 2: 0.004686120200535479\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 1, 0) and action 0: 0.16074340264230014\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 1, 0) and action 2: 0.0023430601002677395\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 1, 0) and action 2: -0.008183085137204303\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 1, 0) and action 2: 0.0011715300501338698\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 1, 0) and action 2: -0.004091542568602152\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 1, 0) and action 2: 0.0005857650250669349\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 1, 0) and action 0: 0.08037170132115007\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 1, 0) and action 1: 0.34474211869012505\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 7, 1, 0) and action 0: 0.040185850660575034\n",
      "Debug: Before Update - Q_value Right for state (2, 7, 1, 0) and action 1: 0.17237105934506253\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 1, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: -1, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 3, 1) and action 0: 0.21919457383356905\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 3, 1) and action 1: -0.014995894726179904\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -1.1053142819662737e-08\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 1.4037045418618688e-06\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 1.2464744394411985e-07\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -5.80892524040299e-08\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -5.526571409831369e-09\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -2.904462620201495e-08\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 2: 6.232372197205992e-08\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 7.046854298268746e-09\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -2.7632857049156843e-09\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 7.018522709309344e-07\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -1.3816428524578422e-09\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 0: 3.509261354654672e-07\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -6.908214262289211e-10\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 3.523427149134373e-09\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 2: -0.13046983233084442\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 1.7617135745671864e-09\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 2: -0.06523491616542221\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 8.808567872835932e-10\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 0: 0.10185806789722679\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 4.404283936417966e-10\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (2, 4, 2, 1) and action 1: -3.4541071311446054e-10\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 2.202141968208983e-10\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 2: -0.032617458082711104\n",
      "Debug: Before Update - Q_value Right for state (3, 4, 2, 1) and action 2: -0.4215269490210801\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 1: 0.0019779761822598073\n",
      "Debug: Before Update - Q_value Right for state (3, 4, 2, 1) and action 0: -0.9455987897598517\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 1: 0.0009889880911299036\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -1.4522313101007474e-08\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 1: 0.0004944940455649518\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 2: -7.261156550503737e-09\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 1: 0.0002472470227824759\n",
      "Debug: Before Update - Q_value Right for state (2, 4, 2, 1) and action 1: 1.1010709841044915e-10\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 1: 0.00012362351139123796\n",
      "Debug: Before Update - Q_value Right for state (3, 4, 2, 1) and action 2: -0.21076347451054006\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 1: 6.181175569561898e-05\n",
      "Debug: Before Update - Q_value Right for state (3, 4, 2, 1) and action 1: 0.468433964372424\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (4, 4, 2, 1) and action 2: -0.20744049298799516\n",
      "Debug: Before Update - Q_value Right for state (3, 4, 2, 1) and action 1: 0.234216982186212\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 4, 2, 1) and action 2: -0.10372024649399758\n",
      "Debug: Before Update - Q_value Right for state (3, 4, 2, 1) and action 0: -0.47279939487992584\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (4, 4, 2, 1) and action 0: 0.43117904022885023\n",
      "Debug: Before Update - Q_value Right for state (3, 4, 2, 1) and action 1: 0.117108491093106\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 0: 0.050929033948613395\n",
      "Debug: Before Update - Q_value Right for state (3, 4, 2, 1) and action 2: -0.10538173725527003\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 1: 3.090587784780949e-05\n",
      "Debug: Before Update - Q_value Right for state (3, 4, 2, 1) and action 0: -0.23639969743996292\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 4, 2, 1) and action 0: 0.025464516974306697\n",
      "Debug: Before Update - Q_value Right for state (3, 4, 2, 1) and action 2: -0.052690868627635015\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 2, 1) and action 1: -0.3414345457185497\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 2, 1) and action 1: -0.3976572686607164\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 0.00020673067472856688\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 1: -0.004324782230212713\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 0.00022713353927139888\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -0.00014263723891910486\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 0.00011356676963569944\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 2: -0.026351335168738887\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -1.2897458596951262e-05\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -7.131861945955243e-05\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 5.678338481784972e-05\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -3.5659309729776215e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 0.00010336533736428344\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -1.7829654864888108e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 5.168266868214172e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 1.5757812681912547e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 2.839169240892486e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -1.392274031857961e-07\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 1.419584620446243e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -6.961370159289805e-08\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -6.448729298475631e-06\n",
      "Debug: Before Update - Q_value Right for state (3, 5, 1, 1) and action 0: -8.914827432444054e-06\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 7.097923102231215e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 7.878906340956274e-06\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 2.584133434107086e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 2.5394553077272233e-07\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -3.2243646492378155e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 3.939453170478137e-06\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 1.292066717053543e-05\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -3.480685079644903e-08\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 6.460333585267715e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 1.9697265852390684e-06\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -1.6121823246189077e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 9.848632926195342e-07\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -8.060911623094539e-07\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 4.924316463097671e-07\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 3.2301667926338574e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -1.7403425398224513e-08\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 1.6150833963169287e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -8.701712699112257e-09\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 0: 3.5489615511156075e-06\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 2: 1.2697276538636116e-07\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -4.0304558115472694e-07\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 2.4621582315488355e-07\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 8.075416981584644e-07\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 0: 1.2310791157744178e-07\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 1: -2.0152279057736347e-07\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -4.350856349556128e-09\n",
      "Debug: Before Update - Q_value Left for state (3, 5, 1, 1) and action 2: 4.037708490792322e-07\n",
      "Debug: Before Update - Q_value Right for state (2, 5, 1, 1) and action 1: -2.175428174778064e-09\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 1, 1) and action 0: 0.19618935358053402\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 1, 1) and action 0: 0.44432533176323774\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 2: 0.001845992949696348\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 2: -0.0006809904688644104\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 1: 0.0006618571829459675\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -1.4186915386742181e-05\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 0: -0.0027365456369108036\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -7.093457693371091e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 0: -0.0013682728184554018\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 2: -0.0003404952344322052\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 2: 0.000922996474848174\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -3.5945718483864967e-07\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 2: 0.000461498237424087\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 2: -0.0001702476172161026\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Mismatch in Q_value Right Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Right: 0, Best Next Action Right: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 2: 0.0002307491187120435\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -3.5467288466855454e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 1: 0.00033092859147298374\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 1: -1.7733644233427727e-06\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n",
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 0: -0.0006841364092277009\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -1.7972859241932483e-07\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Before Update - Q_value Left for state (3, 6, 0, 1) and action 1: 0.00016546429573649187\n",
      "Debug: Before Update - Q_value Right for state (2, 6, 0, 1) and action 0: -8.986429620966242e-08\n",
      "Debug: Mismatch in Q_value Left Update!\n",
      "Alpha: 0.5, Gamma: 0.9, Reward Left: 0, Best Next Action Left: 0\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import random\n",
    "import numpy as np  \n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "\n",
    "#Helper function to load data from a pickle file\n",
    "def load_data_from_pickle_file(filename, default_value):\n",
    "    try: return pickle.load(open(filename, \"rb\")) if os.path.exists(filename) else default_value\n",
    "    except Exception as e: print(f\"Error loading {filename}: {e}\"); return default_value\n",
    "\n",
    "#Constants\n",
    "DATA_FILE_PREFIX = 'v23-'\n",
    "Q_TABLE_LEFT_FILE = 'data/' + DATA_FILE_PREFIX + 'Q_table_left.pkl'\n",
    "Q_TABLE_RIGHT_FILE = 'data/' + DATA_FILE_PREFIX + 'Q_table_right.pkl'\n",
    "EPISODE_COUNT_FILE = 'data/' + DATA_FILE_PREFIX + 'Episode_count.pkl'\n",
    "DEBUG_OFF = 0\n",
    "DEBUG_INFO = 1\n",
    "DEBUG_DEBUG = 2\n",
    "DEBUG_LEVEL = DEBUG_OFF # Default debug level setting\n",
    "GAME_BOARD_GRID_SIZE = 100\n",
    "\n",
    "# Initialize epsilon for the epsilon-greedy policy\n",
    "epsilon = 1.0 #(orig 1.0)\n",
    "epsilon_min = 0.10 #(orig .01)\n",
    "epsilon_decay = 0.9995 #(orig .995)\n",
    "\n",
    "# Initialize hyperparameters\n",
    "alpha = 0.5  # Learning rate (orig .1)\n",
    "gamma = 0.90  # Discount factor (orig .99)\n",
    "\n",
    "#Rewards lookback period (for debugging, not training)\n",
    "reward_lookback_period = 100  # Number of episodes to average over\n",
    "recent_rewards_left = []\n",
    "recent_rewards_right = []\n",
    "\n",
    "# Initialize Q-tables\n",
    "Q_table_left = {}\n",
    "Q_table_right = {}\n",
    "\n",
    "#Q-table save frequency\n",
    "episode_count = 0  # Initialize episode count\n",
    "save_frequency = 100  # Save every 100 episodes\n",
    "\n",
    "#Load data from pickle\n",
    "Q_table_left = load_data_from_pickle_file(Q_TABLE_RIGHT_FILE, {})\n",
    "Q_table_right = load_data_from_pickle_file(Q_TABLE_RIGHT_FILE, {})\n",
    "episode_count = load_data_from_pickle_file(EPISODE_COUNT_FILE, 0)\n",
    "\n",
    "# Initialize scores\n",
    "left_score = 0\n",
    "right_score = 0\n",
    "\n",
    "# Define the action space\n",
    "action_space = [0, 1, 2]  # 0: Move Up, 1: Move Down, 2: Stay Still\n",
    "\n",
    "# Initialize reward\n",
    "reward = 0\n",
    "\n",
    "# Initialize iterations_this_game\n",
    "iterations_this_game = 0\n",
    "\n",
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Create a window\n",
    "width, height = 800, 600  # Window dimensions\n",
    "window = pygame.display.set_mode((width, height))\n",
    "pygame.display.set_caption('Pong Game')\n",
    "\n",
    "# Initialize paddle and ball attributes\n",
    "paddle_width, paddle_height = 20, 100\n",
    "ball_radius = 15\n",
    "\n",
    "# Initial positions\n",
    "left_paddle_pos = [50, height // 2 - paddle_height // 2]\n",
    "right_paddle_pos = [width - 50 - paddle_width, height // 2 - paddle_height // 2]\n",
    "ball_pos = [width // 2, height // 2]\n",
    "\n",
    "# Ball velocity\n",
    "ball_velocity = [random.choice([-4, 4]), random.choice([-4, 4])]\n",
    "\n",
    "#Convert input coordinate to discrete grid space.  this smaller grid space should make learning easier.\n",
    "def discretize_grid(coordinate): \n",
    "    return coordinate // GAME_BOARD_GRID_SIZE\n",
    "\n",
    "#Convert velocity into discretized space (of only 4 options!)\n",
    "def discretize_velocity(velocity_x, velocity_y):\n",
    "    if velocity_x > 0 and velocity_y > 0:\n",
    "        return 0  # Up-Right\n",
    "    elif velocity_x > 0 and velocity_y < 0:\n",
    "        return 1  # Down-Right\n",
    "    elif velocity_x < 0 and velocity_y > 0:\n",
    "        return 2  # Up-Left\n",
    "    elif velocity_x < 0 and velocity_y < 0:\n",
    "        return 3  # Down-Left\n",
    "\n",
    "# Main game loop\n",
    "run = True\n",
    "while run:\n",
    "    #pygame.time.delay(10)\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            run = False\n",
    "            \n",
    "    #Track game loops in this episode/game and report to screen to get a sense of how many loops a game lasts\n",
    "    iterations_this_game += 1\n",
    "    \n",
    "    # Reset rewards to 0 at the beginning of each pass through the game loop\n",
    "    reward_left = 0\n",
    "    reward_right = 0\n",
    "            \n",
    "    # Create the state representation for both agents\n",
    "    state_left = (discretize_grid(left_paddle_pos[1]), discretize_grid(ball_pos[0]), discretize_grid(ball_pos[1]), discretize_velocity(ball_velocity[0], ball_velocity[1]))\n",
    "    state_right = (discretize_grid(right_paddle_pos[1]), discretize_grid(ball_pos[0]), discretize_grid(ball_pos[1]), discretize_velocity(ball_velocity[0], ball_velocity[1]))\n",
    "\n",
    "    # Initialize Q-values for the states if not already present\n",
    "    if state_left not in Q_table_left:\n",
    "        Q_table_left[state_left] = {action: np.random.uniform(-1, 1) for action in action_space}\n",
    "    if state_right not in Q_table_right:\n",
    "        Q_table_right[state_right] = {action: np.random.uniform(-1, 1) for action in action_space}\n",
    "\n",
    "    # Choose an action for both agents using the epsilon-greedy policy\n",
    "    action_left = max(Q_table_left[state_left], key=Q_table_left[state_left].get) if np.random.rand() >= epsilon else np.random.choice(action_space)\n",
    "    action_right = max(Q_table_right[state_right], key=Q_table_right[state_right].get) if np.random.rand() >= epsilon else np.random.choice(action_space)\n",
    "   \n",
    "    # Manual human paddle movement with boundary checks\n",
    "    #keys = pygame.key.get_pressed()\n",
    "    #if keys[pygame.K_w] and left_paddle_pos[1] > 0:\n",
    "    #    left_paddle_pos[1] -= 5\n",
    "    #if keys[pygame.K_s] and left_paddle_pos[1] < height - paddle_height:\n",
    "    #    left_paddle_pos[1] += 5\n",
    "    #if keys[pygame.K_UP] and right_paddle_pos[1] > 0:\n",
    "    #    right_paddle_pos[1] -= 5\n",
    "    #if keys[pygame.K_DOWN] and right_paddle_pos[1] < height - paddle_height:\n",
    "    #    right_paddle_pos[1] += 5\n",
    "\n",
    "    #Left AI agent moves the paddle!!\n",
    "    if action_left == 0 and left_paddle_pos[1] > 0:  # Move Up\n",
    "        left_paddle_pos[1] -= 15\n",
    "    elif action_left == 1 and left_paddle_pos[1] < height - paddle_height:  # Move Down\n",
    "        left_paddle_pos[1] += 15\n",
    "    #elif action_left == 2: \n",
    "        # Stay Still, so no movement\n",
    "        \n",
    "    #Right AI agent moves the paddle!!\n",
    "    if action_right == 0 and right_paddle_pos[1] > 0:  # Move Up\n",
    "        right_paddle_pos[1] -= 15\n",
    "    elif action_right == 1 and right_paddle_pos[1] < height - paddle_height:  # Move Down\n",
    "        right_paddle_pos[1] += 15\n",
    "    #elif action_right == 2: \n",
    "        # Stay Still, so no movement\n",
    "\n",
    "    # Update ball position\n",
    "    ball_pos[0] += ball_velocity[0]\n",
    "    ball_pos[1] += ball_velocity[1]\n",
    "\n",
    "    # Collision detection with walls\n",
    "    if ball_pos[1] <= 0 or ball_pos[1] >= height:\n",
    "        ball_velocity[1] = -ball_velocity[1]\n",
    "\n",
    "    #Debug track whether we have a rewarded event in this loop\n",
    "    reward_applied_this_loop = False\n",
    "    \n",
    "    # Collision detection with paddles\n",
    "    collision_offset = 5  # Define an offset to push the ball away from the paddle\n",
    "    if (left_paddle_pos[0] <= ball_pos[0] <= left_paddle_pos[0] + paddle_width and\n",
    "        left_paddle_pos[1] <= ball_pos[1] <= left_paddle_pos[1] + paddle_height):\n",
    "        ball_velocity[0] = -ball_velocity[0]\n",
    "        ball_pos[0] += collision_offset  # Push the ball away from the paddle\n",
    "        reward_left = 1  # Add reward for left agent\n",
    "        reward_applied_this_loop = True\n",
    "    elif (right_paddle_pos[0] <= ball_pos[0] <= right_paddle_pos[0] + paddle_width and\n",
    "          right_paddle_pos[1] <= ball_pos[1] <= right_paddle_pos[1] + paddle_height):\n",
    "        ball_velocity[0] = -ball_velocity[0]\n",
    "        ball_pos[0] -= collision_offset  # Push the ball away from the paddle\n",
    "        reward_right = 1  # Add reward for right agent\n",
    "        reward_applied_this_loop = True\n",
    "    \n",
    "    #Penalties for not exploring enough\n",
    "    #extreme_zones = [[0, height // 8], [7 * height // 8, height]]  # Define the extreme zones\n",
    "    #bonus = 0.1  # Define the bonus\n",
    "    #center_zone = [height // 4, 3 * height // 4]  # Define the center zone\n",
    "    #penalty = -0.1  # Define the penalty\n",
    "    # Apply penalty for center zone\n",
    "    #if center_zone[0] <= left_paddle_pos[1] <= center_zone[1]:\n",
    "    #    reward_left += penalty\n",
    "    #if center_zone[0] <= right_paddle_pos[1] <= center_zone[1]:\n",
    "    #    reward_right += penalty\n",
    "    # Apply bonus for extreme zones\n",
    "    #for zone in extreme_zones:\n",
    "    #    if zone[0] <= left_paddle_pos[1] <= zone[1]:\n",
    "    #        reward_left += bonus\n",
    "    #    if zone[0] <= right_paddle_pos[1] <= zone[1]:\n",
    "    #        reward_right += bonus\n",
    "        \n",
    "    # Ball reset, scoring, and immediate feedback game-over condition\n",
    "    if ball_pos[0] < 0:\n",
    "        # Reset paddle positions to the middle\n",
    "        left_paddle_pos = [50, height // 2 - paddle_height // 2]\n",
    "        right_paddle_pos = [width - 50 - paddle_width, height // 2 - paddle_height // 2]\n",
    "        #Reset the ball to the center in a random direction\n",
    "        ball_pos = [width // 2, height // 2]\n",
    "        ball_velocity = [random.choice([-4, 4]), random.choice([-4, 4])]\n",
    "        #Scoring\n",
    "        right_score += 1  # Right player scores\n",
    "        #Rewards\n",
    "        reward_left += -1  # Negative reward for the left agent\n",
    "        reward_right += 1  # Positive reward for the right agent\n",
    "        reward_applied_this_loop = True\n",
    "        #Signal the end of an episode\n",
    "        episode_count += 1  # Increment episode count\n",
    "        iterations_this_game = 0\n",
    "        # Decay epsilon at the end of a game/episode\n",
    "        if epsilon > epsilon_min:\n",
    "            epsilon *= epsilon_decay\n",
    "        # Save the Q-tables every save_frequency episodes\n",
    "        if episode_count % save_frequency == 0:\n",
    "            with open(Q_TABLE_LEFT_FILE, \"wb\") as f:\n",
    "                pickle.dump(Q_table_left, f)\n",
    "            with open(Q_TABLE_RIGHT_FILE, \"wb\") as f:\n",
    "                pickle.dump(Q_table_right, f)\n",
    "            with open(EPISODE_COUNT_FILE, \"wb\") as f:\n",
    "                pickle.dump(episode_count, f)\n",
    "    elif ball_pos[0] > width:\n",
    "        # Reset paddle positions to the middle\n",
    "        left_paddle_pos = [50, height // 2 - paddle_height // 2]\n",
    "        right_paddle_pos = [width - 50 - paddle_width, height // 2 - paddle_height // 2]\n",
    "        #Reset the ball to the center in a random direction\n",
    "        ball_pos = [width // 2, height // 2]\n",
    "        ball_velocity = [random.choice([-4, 4]), random.choice([-4, 4])]\n",
    "        #Scoring\n",
    "        left_score += 1  # Left player scores\n",
    "        #Rewards\n",
    "        reward_left += 1  # Positive reward for the left agent\n",
    "        reward_right += -1  # Negative reward for the right agent\n",
    "        reward_applied_this_loop = True\n",
    "        #Signal the end of an episode\n",
    "        episode_count += 1  # Increment episode count\n",
    "        iterations_this_game = 0\n",
    "        # Decay epsilon at the end of a game/episode\n",
    "        if epsilon > epsilon_min:\n",
    "            epsilon *= epsilon_decay\n",
    "        # Save the Q-tables every save_frequency episodes\n",
    "        if episode_count % save_frequency == 0:\n",
    "            with open(Q_TABLE_LEFT_FILE, \"wb\") as f:\n",
    "                pickle.dump(Q_table_left, f)\n",
    "            with open(Q_TABLE_RIGHT_FILE, \"wb\") as f:\n",
    "                pickle.dump(Q_table_right, f)\n",
    "            with open(EPISODE_COUNT_FILE, \"wb\") as f:\n",
    "                pickle.dump(episode_count, f)\n",
    "                \n",
    "    # After taking an action, observe new state and reward\n",
    "    new_state_left = (discretize_grid(left_paddle_pos[1]), right_paddle_pos[1], discretize_grid(ball_pos[0]), discretize_grid(ball_pos[1]), discretize_velocity(ball_velocity[0], ball_velocity[1]))\n",
    "    new_state_right = (discretize_grid(left_paddle_pos[1]), right_paddle_pos[1], discretize_grid(ball_pos[0]), discretize_grid(ball_pos[1]), discretize_velocity(ball_velocity[0], ball_velocity[1]))\n",
    "\n",
    "    # Initialize Q-values-left for the new state if not already present\n",
    "    if new_state_left not in Q_table_left:\n",
    "        Q_table_left[new_state_left] = {action: 0 for action in action_space}\n",
    "\n",
    "    # Initialize Q-values-right for the new state if not already present\n",
    "    if new_state_right not in Q_table_right:\n",
    "        Q_table_right[new_state_right] = {action: 0 for action in action_space}\n",
    "\n",
    "    # Calculate the best next action for both agents\n",
    "    best_next_action_left = max(Q_table_left[new_state_left], key=Q_table_left[new_state_left].get)\n",
    "    best_next_action_right = max(Q_table_right[new_state_right], key=Q_table_right[new_state_right].get)\n",
    "\n",
    "    # Debug: Print Q-values before update\n",
    "    if new_state_left in Q_table_left and state_left in Q_table_left:\n",
    "        print(f\"Debug: Before Update - Q_value Left for state {state_left} and action {action_left}: {Q_table_left[state_left][action_left]}\")\n",
    "\n",
    "    if new_state_right in Q_table_right and state_right in Q_table_right:\n",
    "        print(f\"Debug: Before Update - Q_value Right for state {state_right} and action {action_right}: {Q_table_right[state_right][action_right]}\")\n",
    "\n",
    "    # Q-Learning update rule for both agents\n",
    "    Q_table_left[state_left][action_left] = (1 - alpha) * Q_table_left[state_left][action_left] + alpha * (reward_left + gamma * Q_table_left[new_state_left][best_next_action_left])\n",
    "    Q_table_right[state_right][action_right] = (1 - alpha) * Q_table_right[state_right][action_right] + alpha * (reward_right + gamma * Q_table_right[new_state_right][best_next_action_right])\n",
    "\n",
    "    # Debug: Check for approximate equality\n",
    "    tolerance = 1e-5  # You can adjust this value\n",
    "    if abs(Q_table_left[state_left][action_left] - ((1 - alpha) * Q_table_left[state_left][action_left] + alpha * (reward_left + gamma * Q_table_left[new_state_left][best_next_action_left]))) > tolerance:\n",
    "        print(f\"Debug: Mismatch in Q_value Left Update!\")\n",
    "        print(f\"Alpha: {alpha}, Gamma: {gamma}, Reward Left: {reward_left}, Best Next Action Left: {best_next_action_left}\")\n",
    "\n",
    "    if abs(Q_table_right[state_right][action_right] - ((1 - alpha) * Q_table_right[state_right][action_right] + alpha * (reward_right + gamma * Q_table_right[new_state_right][best_next_action_right]))) > tolerance:\n",
    "        print(f\"Debug: Mismatch in Q_value Right Update!\")\n",
    "        print(f\"Alpha: {alpha}, Gamma: {gamma}, Reward Right: {reward_right}, Best Next Action Right: {best_next_action_right}\")\n",
    "    \n",
    "    # Update current state for next iteration\n",
    "    state_left = new_state_left\n",
    "    state_right = new_state_right\n",
    "         \n",
    "    # Append the reward of the current episode to the list\n",
    "    recent_rewards_left.append(reward_left)\n",
    "    recent_rewards_right.append(reward_right)\n",
    "    # Remove the oldest reward if the list grows too large\n",
    "    if len(recent_rewards_left) > reward_lookback_period:\n",
    "        del recent_rewards_left[0]\n",
    "    if len(recent_rewards_right) > reward_lookback_period:\n",
    "        del recent_rewards_right[0]\n",
    "    # Calculate the average reward\n",
    "    avg_reward_left = sum(recent_rewards_left) / len(recent_rewards_left)\n",
    "    avg_reward_right = sum(recent_rewards_right) / len(recent_rewards_right)\n",
    "        \n",
    "    # Draw paddles, ball, and scores\n",
    "    window.fill((0, 0, 0))  # Clear screen\n",
    "    pygame.draw.rect(window, (255, 255, 255), left_paddle_pos + [paddle_width, paddle_height])\n",
    "    pygame.draw.rect(window, (255, 255, 255), right_paddle_pos + [paddle_width, paddle_height])\n",
    "    pygame.draw.circle(window, (255, 255, 255), ball_pos, ball_radius)\n",
    "\n",
    "    # Display scores\n",
    "    font = pygame.font.SysFont(None, 30)\n",
    "    score_display = font.render(f\"score: {left_score} - {right_score}\", True, (255, 255, 255))\n",
    "    window.blit(score_display, (width // 2 - 45, 10))\n",
    "    \n",
    "    # Display episode count\n",
    "    font = pygame.font.SysFont(None, 30)\n",
    "    episode_display = font.render(f\"episodes played: {episode_count}\", True, (255, 255, 255))\n",
    "    window.blit(episode_display, (width // 2 - 100, 40))\n",
    "    \n",
    "    # Display current epsilon\n",
    "    font = pygame.font.SysFont(None, 30)\n",
    "    epsilon_display = font.render(f\"Epsilon: {epsilon:.4f}\", True, (255, 255, 255))\n",
    "    window.blit(epsilon_display, (10, 70))\n",
    "\n",
    "    # Display average reward for left and right agents\n",
    "    font = pygame.font.SysFont(None, 30)\n",
    "    avg_reward_left_display = font.render(f\"Avg Reward Left: {avg_reward_left:.6f}\", True, (255, 255, 255))\n",
    "    window.blit(avg_reward_left_display, (10, 100))\n",
    "    avg_reward_right_display = font.render(f\"Avg Reward Right: {avg_reward_right:.6f}\", True, (255, 255, 255))\n",
    "    window.blit(avg_reward_right_display, (10, 130))\n",
    "    \n",
    "    # Display current frame within game\n",
    "    #font = pygame.font.SysFont(None, 30)\n",
    "    #epsilon_display = font.render(f\"iterations_this_game: {iterations_this_game}\", True, (255, 255, 255))\n",
    "    #window.blit(epsilon_display, (10, 160))\n",
    "    \n",
    "    if (DEBUG_LEVEL>=DEBUG_DEBUG): \n",
    "        if Q_table_left[state_left][action_left] != 0:\n",
    "            print(f\"Episode: {episode_count}, Iteration: {iterations_this_game}\")\n",
    "            print(f\"Current State Left: {state_left}, Action Left: {action_left}, Q-Value: {Q_table_left[state_left][action_left]}\")\n",
    "            print(f\"New State Left: {new_state_left}, Best Next Action Left: {best_next_action_left}, Q-Value: {Q_table_left[new_state_left][best_next_action_left]}\")\n",
    "            print(f\"Reward Left: {reward_left}\")\n",
    "            print(f\"Current Epsilon: {epsilon}\")\n",
    "            #print(f\"Avg Reward Left: {avg_reward_left}\")\n",
    "            print(f\"----------\")\n",
    "            print(f\" \")\n",
    "\n",
    "\n",
    "    pygame.display.update()\n",
    "    \n",
    "pygame.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2739a9",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e462cd2",
   "metadata": {},
   "source": [
    "## Implementing Game Mechanics for Pong\n",
    "\n",
    "### 1. Initialize Pygame and Create Window\n",
    "- Initialized Pygame and created an 800x600 window for the game.\n",
    "\n",
    "### 2. Initialize Paddle and Ball Attributes\n",
    "- Defined the dimensions of the paddles and the ball. Initialized their starting positions.\n",
    "\n",
    "### 3. Paddle Movement\n",
    "- Implemented keyboard controls for moving the paddles up and down.\n",
    "\n",
    "### 4. Ball Movement and Collision Detection\n",
    "- Added logic for ball movement and collision detection with the walls and paddles.\n",
    "\n",
    "### 5. Ball Reset and Scoring\n",
    "- Implemented ball reset and scoring mechanics. The ball resets to the center after a point is scored.\n",
    "\n",
    "### 6. Paddle Boundaries\n",
    "- Added boundaries to prevent the paddles from moving out of the window.\n",
    "\n",
    "### 7. Game Over Conditions\n",
    "- Implemented immediate feedback game-over conditions. The game resets after each point, serving as an episode in RL terms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0693c8",
   "metadata": {},
   "source": [
    "## Defining RL Elements for Pong\n",
    "\n",
    "### 1. State Representation\n",
    "- Decide how to represent the state of the game. Consider the trade-offs between granularity and computational complexity.\n",
    "\n",
    "### 2. Action Space\n",
    "- Define the set of actions I can take (e.g., move paddle up, move paddle down, stay still).\n",
    "\n",
    "### 3. Reward Structure\n",
    "- Design the rewards I receive for various outcomes (e.g., +1 for scoring, -1 for opponent scoring).\n",
    "\n",
    "### 4. Policy Initialization\n",
    "- Initialize my policy, which could be a Q-table, a neural network, or some other function mapping states to actions.\n",
    "\n",
    "### 5. Learning Algorithm\n",
    "- Choose and implement a learning algorithm (e.g., Q-learning, SARSA, Deep Q-Networks) to update my policy based on experiences.\n",
    "\n",
    "### 6. Exploration-Exploitation Strategy\n",
    "- Decide on a strategy for balancing exploration (trying new actions) and exploitation (sticking with known good actions), such as ε-greedy.\n",
    "\n",
    "### 7. Training Loop\n",
    "- Implement the training loop where I interact with the environment, update my policy, and optionally log metrics like average reward over time.\n",
    "\n",
    "### 8. Evaluation Metrics\n",
    "- Define metrics to evaluate my performance (e.g., average reward, win rate).\n",
    "\n",
    "### 9. Hyperparameter Tuning\n",
    "- Experiment with different learning rates, discount factors, and other hyperparameters to optimize performance.\n",
    "\n",
    "### 10. Testing and Validation\n",
    "- Test the trained agent to see how well it performs and validate that it is learning effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2002e88",
   "metadata": {},
   "source": [
    "## Q-Learning Algorithm\n",
    "\n",
    "Q-Learning is a model-free reinforcement learning algorithm that aims to learn a policy, which tells an agent what action to take under what circumstances. It defines a function \\( Q(s, a) \\), representing the quality or the utility of taking action \\( a \\) in state \\( s \\).\n",
    "\n",
    "### Outline\n",
    "\n",
    "1. **Initialize Q-Table**: Create a table to store the Q-values for each state-action pair.\n",
    "2. **Policy**: Define how the agent chooses an action (e.g., \\(\\epsilon\\)-greedy).\n",
    "3. **Learning**: Update the Q-values using the Q-Learning update rule.\n",
    "4. **Training Loop**: Incorporate these elements into the game loop.\n",
    "\n",
    "The Q-table will be represented as a Python dictionary. The keys will be the states, and the values will be another dictionary mapping actions to Q-values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e387d6",
   "metadata": {},
   "source": [
    "## max() reference\n",
    "\n",
    "| Iterable Type | What It Returns to `max()` | Example of Using `max()` |\n",
    "|---------------|----------------------------|--------------------------|\n",
    "| List          | Individual list elements   | `max([1, 2, 3])` returns `3` |\n",
    "| Tuple         | Individual tuple elements  | `max((1, 2, 3))` returns `3` |\n",
    "| String        | Individual characters     | `max(\"abc\")` returns `'c'` |\n",
    "| Set           | Individual set elements    | `max({1, 2, 3})` returns `3` |\n",
    "| Dictionary    | Dictionary keys           | `max({'a': 1, 'b': 2}, key=lambda k: k)` returns `'b'` |\n",
    "|               |                            | `max({'a': 1, 'b': 2}.values())` returns `2` |\n",
    "|               |                            | `max({'a': 1, 'b': 2}, key=lambda k: {'a': 1, 'b': 2}[k])` returns `'b'` |\n",
    "| Numpy Array   | Individual array elements  | `import numpy as np; max(np.array([1, 2, 3]))` returns `3` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9b3475",
   "metadata": {},
   "source": [
    "## Building intuition around training variables\n",
    "\n",
    "1. **Alpha (α) - Learning Rate**: \n",
    "    - **What it does**: Determines how much of the new Q-value estimate I adopt.\n",
    "    - **Intuition**: Think of it as a \"blending factor.\" If α is 1, I consider only the most recent information. If α is 0, I learn nothing and stick to my prior knowledge. A value between 0 and 1 blends the old and new information.\n",
    "    - **Example**: If α is high (closer to 1), I will rapidly adapt to new strategies but may also forget useful past knowledge quickly.\n",
    "\n",
    "2. **Gamma (γ) - Discount Factor**: \n",
    "    - **What it does**: Influences how much future rewards contribute to the Q-value.\n",
    "    - **Intuition**: It's like a \"patience meter.\" A high γ makes me prioritize long-term reward over short-term reward.\n",
    "    - **Example**: If γ is close to 1, I will consider future rewards with greater weight, making me more strategic but potentially slower to train.\n",
    "\n",
    "3. **Epsilon (ε) - Exploration Rate**: \n",
    "    - **What it does**: Controls the trade-off between exploration (trying new actions) and exploitation (sticking with known actions).\n",
    "    - **Intuition**: It's like the \"curiosity level.\" A high ε encourages me to try new things, while a low ε makes me stick to what I know.\n",
    "    - **Example**: If ε starts high and decays over time (ε-decay), I will initially explore a lot and gradually shift to exploiting my learned knowledge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b10bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PongReinforcementLearningVENV",
   "language": "python",
   "name": "pongreinforcementlearningvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
